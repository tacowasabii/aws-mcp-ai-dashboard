# LLM + AWS MCP Dashboard Environment Configuration

# ===========================================
# LLM API Keys (Required - Choose one or both)
# ===========================================

# OpenAI API Key (for GPT models)
# Get from: https://platform.openai.com/api-keys
OPENAI_API_KEY=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

# Anthropic API Key (for Claude models)
# Get from: https://console.anthropic.com/settings/keys
ANTHROPIC_API_KEY=sk-ant-your-anthropic-api-key-here

# ===========================================
# AWS MCP Server Configuration
# ===========================================

# AWS MCP Server URL (if running externally)
# Default: http://localhost:3001
AWS_MCP_SERVER_URL=http://localhost:3001

# AWS MCP Request Timeout (milliseconds)
# Default: 30000 (30 seconds)
AWS_MCP_TIMEOUT=30000

# ===========================================
# Application Configuration
# ===========================================

# Application Environment
NODE_ENV=development

# Public Application URL
NEXT_PUBLIC_APP_URL=http://localhost:3000

# ===========================================
# AWS Credentials (NOT USED - User Input Only)
# ===========================================
# Note: This application does NOT use environment AWS credentials
# Users must input their AWS credentials through the UI
# The credentials are then passed to the LLM + MCP system

# ===========================================
# Setup Instructions
# ===========================================
# 1. Copy this file to .env.local
# 2. Fill in your LLM API keys
# 3. Start the application: npm run dev
# 4. Add AWS accounts through the UI
# 5. Chat with your AWS resources using natural language!

# ===========================================
# Security Notes
# ===========================================
# - Never commit actual API keys to git
# - Keep .env.local in .gitignore
# - AWS credentials are provided by users through UI only
# - All AWS operations go through LLM + MCP, never direct SDK